{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhojun12\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hojun/Documents/project/js/pytorch_template/wandb/run-20240409_031021-esx11hjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hojun12/asksalk/runs/esx11hjp' target=\"_blank\">askal</a></strong> to <a href='https://wandb.ai/hojun12/asksalk' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hojun12/asksalk' target=\"_blank\">https://wandb.ai/hojun12/asksalk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hojun12/asksalk/runs/esx11hjp' target=\"_blank\">https://wandb.ai/hojun12/asksalk/runs/esx11hjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "Epoch 0/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [00:55<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0544959015192643\n",
      "Epoch 0/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_id': 0, 'train_serial': '20240409_031019', 'lr': [0.0005], 'train_loss': 1.0544959015192643, 'train_f1-score': 0.33419135779380293, 'train_elapsed_time': 55.2, 'val_loss': 1.043534079939127, 'val_f1-score': 0.4989326371869541, 'val_elapsed_time': 7.2}\n",
      "{'epoch_id': 0, 'train_serial': '20240409_031019', 'lr': 0.0005, 'train_loss': 1.0544959015192643, 'train_f1-score': 0.33419135779380293, 'train_elapsed_time': 55.2, 'val_loss': 1.043534079939127, 'val_f1-score': 0.4989326371869541, 'val_elapsed_time': 7.2}\n",
      "Epoch 1/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 321/321 [00:54<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.042225310364245\n",
      "Epoch 1/100 Validation..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:07<00:00, 11.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch_id': 1, 'train_serial': '20240409_031019', 'lr': [0.0004998766400914329], 'train_loss': 1.042225310364245, 'train_f1-score': 0.33666277213190376, 'train_elapsed_time': 54.7, 'val_loss': 1.0407408431172371, 'val_f1-score': 0.4989326371869541, 'val_elapsed_time': 7.1}\n",
      "{'epoch_id': 1, 'train_serial': '20240409_031019', 'lr': 0.0004998766400914329, 'train_loss': 1.042225310364245, 'train_f1-score': 0.33666277213190376, 'train_elapsed_time': 54.7, 'val_loss': 1.0407408431172371, 'val_f1-score': 0.4989326371869541, 'val_elapsed_time': 7.1}\n",
      "Epoch 2/100 Train..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 162/321 [00:26<00:25,  6.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 166\u001b[0m\n\u001b[1;32m    164\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Train..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m tic \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m--> 166\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m toc \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Write tarin result to result row\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/project/js/pytorch_template/modules/trainer.py:53\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, dataloader, epoch_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Update\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/project/js/pytorch_template/modules/losses.py:31\u001b[0m, in \u001b[0;36mCCE.forward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, targets):\n\u001b[1;32m     30\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(inputs, targets, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m---> 31\u001b[0m     unique_values, unique_counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     selected_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, index\u001b[38;5;241m=\u001b[39munique_values)\n\u001b[1;32m     34\u001b[0m     numerator \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum()                               \u001b[38;5;66;03m# weighted losses\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/_jit_internal.py:499\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     dispatch_flag \u001b[38;5;241m=\u001b[39m args[arg_index]\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch_flag:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_true\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_false(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/functional.py:981\u001b[0m, in \u001b[0;36m_return_counts\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 981\u001b[0m output, _, counts \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, counts\n",
      "File \u001b[0;32m~/anaconda3/envs/fp_mlfow/lib/python3.10/site-packages/torch/functional.py:905\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    897\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39munique_dim(\n\u001b[1;32m    898\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    899\u001b[0m         dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    902\u001b[0m         return_counts\u001b[38;5;241m=\u001b[39mreturn_counts,\n\u001b[1;32m    903\u001b[0m     )\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"Train\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import numpy as np\n",
    "import shutil, random, os, sys, torch\n",
    "from glob import glob\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "prj_dir = os.getcwd()\n",
    "sys.path.append(prj_dir)\n",
    "\n",
    "from modules.utils import load_yaml, get_logger\n",
    "from modules.metrics import get_metric_function\n",
    "from modules.earlystoppers import EarlyStopper\n",
    "from modules.losses import get_loss_function\n",
    "from modules.optimizers import get_optimizer\n",
    "from modules.schedulers import get_scheduler\n",
    "from modules.scalers import get_image_scaler\n",
    "from modules.transforms import get_transform_function\n",
    "from modules.datasets import get_dataset_function\n",
    "from modules.recorders import Recorder\n",
    "from modules.trainer import Trainer\n",
    "from models.utils import get_model\n",
    "\n",
    "# Load config\n",
    "config_path = os.path.join(prj_dir, 'config', 'train.yaml')\n",
    "config = load_yaml(config_path)\n",
    "\n",
    "# Set train serial: ex) 20211004\n",
    "train_serial = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "train_serial = 'debug' if config['debug'] else train_serial\n",
    "\n",
    "wandb.init(\n",
    "        project=config['project_name'],\n",
    "        config={\n",
    "            \"architecture\": config['model']['model_name'],\n",
    "            \"dataset\": config['dataset_name'],\n",
    "            \"notes\": config['wandb_note'],\n",
    "        },\n",
    "        name=config['run_name'],\n",
    ")\n",
    "\n",
    "# Set random seed, deterministic\n",
    "torch.cuda.manual_seed(config['seed'])\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set device(GPU/CPU)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(config['gpu_num'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create train result directory and set logger\n",
    "train_result_dir = os.path.join(prj_dir, 'results', 'train', train_serial)\n",
    "os.makedirs(train_result_dir, exist_ok=True)\n",
    "\n",
    "# Set logger\n",
    "logging_level = 'debug' if config['verbose'] else 'info'\n",
    "logger = get_logger(name='train',\n",
    "                    file_path=os.path.join(train_result_dir, 'train.log'),\n",
    "                    level=logging_level)\n",
    "\n",
    "\n",
    "# Set data directory\n",
    "train_dirs = os.path.join(prj_dir, 'data', 'train')\n",
    "\n",
    "# Load data and create dataset for train \n",
    "# Load image scaler\n",
    "# train_img_paths = glob(os.path.join(train_dirs, 'x', '*.png'))\n",
    "# train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=config['val_size'], random_state=config['seed'], shuffle=True)\n",
    "transforms = get_transform_function(config['transform_name'],config=config)\n",
    "\n",
    "train_dataset = get_dataset_function(config['dataset_name'])\n",
    "val_dataset = get_dataset_function(config['dataset_name'])\n",
    "train_dataset = train_dataset(config['train_data_path'],transform=transforms)\n",
    "val_dataset = val_dataset(config['val_data_path'],transform=transforms)\n",
    "\n",
    "# train_dataset = train_dataset(paths=train_img_paths,\n",
    "#                         input_size=[config['input_width'], config['input_height']],\n",
    "#                         scaler=get_image_scaler(config['scaler']),\n",
    "#                         logger=logger)\n",
    "# val_dataset = val_dataset(paths=val_img_paths,\n",
    "#                         input_size=[config['input_width'], config['input_height']],\n",
    "#                         scaler=get_image_scaler(config['scaler']),\n",
    "                        # logger=logger)\n",
    "# Create data loader\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=config['shuffle'],\n",
    "                            drop_last=config['drop_last'])\n",
    "                            \n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=config['batch_size'],\n",
    "                            num_workers=config['num_workers'], \n",
    "                            shuffle=False,\n",
    "                            drop_last=config['drop_last'])\n",
    "\n",
    "logger.info(f\"Load dataset, train: {len(train_dataset)}, val: {len(val_dataset)}\")\n",
    "\n",
    "# Load model\n",
    "model = get_model(model_str=config['model']['model_name'])\n",
    "model = model(**config['model']['args']).to(device)\n",
    "logger.info(f\"Load model architecture: {config['model']['model_name']}\")\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = get_optimizer(optimizer_str=config['optimizer']['name'])\n",
    "optimizer = optimizer(model.parameters(), **config['optimizer']['args'])\n",
    "\n",
    "# Set Scheduler\n",
    "scheduler = get_scheduler(scheduler_str=config['scheduler']['name'])\n",
    "scheduler = scheduler(optimizer=optimizer, **config['scheduler']['args'])\n",
    "\n",
    "# Set loss function\n",
    "loss_func = get_loss_function(loss_function_str=config['loss']['name'])\n",
    "loss_func = loss_func(**config['loss']['args'])\n",
    "\n",
    "# Set metric\n",
    "metric_funcs = {metric_name:get_metric_function(metric_name,device) for metric_name in config['metrics']}\n",
    "logger.info(f\"Load optimizer:{config['optimizer']['name']}, scheduler: {config['scheduler']['name']}, loss: {config['loss']['name']}, metric: {config['metrics']}\")\n",
    "\n",
    "# Set trainer\n",
    "trainer = Trainer(model=model,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                loss_func=loss_func,\n",
    "                metric_funcs=metric_funcs,\n",
    "                device=device,\n",
    "                logger=logger)\n",
    "logger.info(f\"Load trainer\")\n",
    "\n",
    "# Set early stopper\n",
    "early_stopper = EarlyStopper(patience=config['earlystopping_patience'],\n",
    "                            logger=logger)\n",
    "# Set recorder\n",
    "recorder = Recorder(record_dir=train_result_dir,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    logger=logger)\n",
    "logger.info(\"Load early stopper, recorder\")\n",
    "\n",
    "# Recorder - save train config\n",
    "shutil.copy(config_path, os.path.join(recorder.record_dir, 'train.yaml'))\n",
    "\n",
    "# Train\n",
    "print(\"START TRAINING\")\n",
    "logger.info(\"START TRAINING\")\n",
    "for epoch_id in range(config['n_epochs']):\n",
    "    \n",
    "    # Initiate result row\n",
    "    row = dict()\n",
    "    row['epoch_id'] = epoch_id\n",
    "    row['train_serial'] = train_serial\n",
    "    row['lr'] = trainer.scheduler.get_last_lr()\n",
    "\n",
    "    # Train\n",
    "    print(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "    logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Train..\")\n",
    "    tic = time()\n",
    "    trainer.train(dataloader=train_dataloader, epoch_index=epoch_id)\n",
    "    toc = time()\n",
    "    # Write tarin result to result row\n",
    "    row['train_loss'] = trainer.loss  # Loss\n",
    "    for metric_name, metric_score in trainer.scores.items():\n",
    "        row[f'train_{metric_name}'] = metric_score\n",
    "\n",
    "    row['train_elapsed_time'] = round(toc-tic, 1)\n",
    "    # Clear\n",
    "    trainer.clear_history()\n",
    "\n",
    "    # Validation\n",
    "    print(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "    logger.info(f\"Epoch {epoch_id}/{config['n_epochs']} Validation..\")\n",
    "    tic = time()\n",
    "    trainer.validate(dataloader=val_dataloader, epoch_index=epoch_id)\n",
    "    toc = time()\n",
    "    row['val_loss'] = trainer.loss\n",
    "    # row[f\"val_{config['metric']}\"] = trainer.score\n",
    "    for metric_name, metric_score in trainer.scores.items():\n",
    "        row[f'val_{metric_name}'] = metric_score\n",
    "    row['val_elapsed_time'] = round(toc-tic, 1)\n",
    "    trainer.clear_history()\n",
    "\n",
    "    # Performance record - row\n",
    "    recorder.add_row(row)\n",
    "    recorder.wandb_mlflow_log(model=model, log_dict=row, sample_image=None)\n",
    "    \n",
    "    # Performance record - plot\n",
    "    recorder.save_plot(config['plot'])\n",
    "\n",
    "    # Check early stopping\n",
    "    early_stopper.check_early_stopping(row[config['earlystopping_target']])\n",
    "    if early_stopper.patience_counter == 0:\n",
    "        recorder.save_weight(epoch=epoch_id)\n",
    "        \n",
    "    if early_stopper.stop:\n",
    "        print(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "        logger.info(f\"Epoch {epoch_id}/{config['n_epochs']}, Stopped counter {early_stopper.patience_counter}/{config['earlystopping_patience']}\")\n",
    "        break\n",
    "\n",
    "print(\"END TRAINING\")\n",
    "logger.info(\"END TRAINING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fp_mlfow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
